{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a4acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import pyspark.ml.evaluation as evals\n",
    "import pyspark.ml.tuning as tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bc0831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001FB2FF0E308>\n"
     ]
    }
   ],
   "source": [
    "# creating a spark session\n",
    "# Import SparkSession from pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create my_spark\n",
    "my_spark = SparkSession.builder.appName('Fundamentals').getOrCreate()\n",
    "my_spark.conf.set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\",\"true\")\n",
    "# Print my_spark\n",
    "print(my_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6d11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = my_spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e32fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of Spark Context in the PySpark shell is 2.4.6\n",
      "The Python version of Spark Context in the PySpark shell is 3.7\n",
      "The master of Spark Context in the PySpark shell is local[*]\n"
     ]
    }
   ],
   "source": [
    "# Print the version of SparkContext\n",
    "print(\"The version of Spark Context in the PySpark shell is\", sc.version)\n",
    "\n",
    "# Print the Python version of SparkContext\n",
    "print(\"The Python version of Spark Context in the PySpark shell is\", sc.pythonVer)\n",
    "\n",
    "# Print the master of SparkContext\n",
    "print(\"The master of Spark Context in the PySpark shell is\", sc.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a383f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range: range(1, 6)\n",
      "rdd (spark): PythonRDD[1] at RDD at PythonRDD.scala:53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Python list of numbers from 1 to 100 \n",
    "numb = range(1, 100)\n",
    "\n",
    "# Load the list into PySpark  \n",
    "spark_data = sc.parallelize(numb)\n",
    "print(f'range: {numb[:5]}')\n",
    "print(f'rdd (spark): {spark_data}')\n",
    "spark_data.collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b964837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rofl. Its true to its name',\n",
       " \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\",\n",
       " 'Pity, * was in mood for that. So...any other suggestions?',\n",
       " 'Will ÃƒÂ¼ b going to esplanade fr home?',\n",
       " 'Huh y lei...']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a local file into PySpark shell\n",
    "lines = sc.textFile('./ham.txt')\n",
    "lines.collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c48f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input list is [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "The squared numbers are [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "my_list = list(range(1, 11))\n",
    "# Print my_list in the console\n",
    "print(\"Input list is\", my_list)\n",
    "\n",
    "# Square all numbers in my_list\n",
    "squared_list_lambda = list(map(lambda x: x ** 2, my_list))\n",
    "\n",
    "# Print the result of the map function\n",
    "print(\"The squared numbers are\", squared_list_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550c9175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input list is: [10, 21, 31, 40, 51, 60, 72, 80, 93, 101]\n",
      "Numbers divisible by 10 are: [10, 40, 60, 80]\n"
     ]
    }
   ],
   "source": [
    "my_list2 = [10, 21, 31, 40, 51, 60, 72, 80, 93, 101]\n",
    "# Print my_list2 in the console\n",
    "print(\"Input list is:\", my_list2)\n",
    "\n",
    "# Filter numbers divisible by 10\n",
    "filtered_list = list(filter(lambda x: (x%10 == 0), my_list2))\n",
    "\n",
    "# Print the numbers divisible by 10\n",
    "print(\"Numbers divisible by 10 are:\", filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909fe119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of RDD is <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD from a list of words\n",
    "RDD = sc.parallelize([\"Spark\", \"is\", \"a\", \"framework\", \"for\", \"Big Data processing\"])\n",
    "\n",
    "# Print out the type of the created object\n",
    "print(\"The type of RDD is\", type(RDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d190f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file type of fileRDD is <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "# Create a fileRDD from file_path\n",
    "file_path = './ham.txt'\n",
    "fileRDD = sc.textFile(file_path)\n",
    "\n",
    "# Check the type of fileRDD\n",
    "print(\"The file type of fileRDD is\", type(fileRDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3325a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions in fileRDD is 2\n",
      "Number of partitions in fileRDD_part is 5\n"
     ]
    }
   ],
   "source": [
    "# Check the number of partitions in fileRDD\n",
    "print(\"Number of partitions in fileRDD is\", fileRDD.getNumPartitions())\n",
    "\n",
    "# Create a fileRDD_part from file_path with 5 partitions\n",
    "fileRDD_part = sc.textFile(file_path, minPartitions = 5)\n",
    "\n",
    "# Check the number of partitions in fileRDD_part\n",
    "print(\"Number of partitions in fileRDD_part is\", fileRDD_part.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ad527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [4, 5], [6], [7], [8], [9, 10]]\n",
      "[[], [1, 3, 7, 8, 9, 10], [2, 4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "RDD_INT = sc.parallelize(range(1, 11))\n",
    "print(RDD_INT.glom().collect())\n",
    "RDD_INT = RDD_INT.repartition(3)\n",
    "print(RDD_INT.glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04cf6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "27\n",
      "64\n",
      "125\n",
      "216\n",
      "343\n",
      "512\n",
      "729\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "numbRDD = sc.parallelize(range(1, 11))\n",
    "# Create map() transformation to cube numbers\n",
    "cubedRDD = numbRDD.map(lambda x: x ** 3)\n",
    "\n",
    "# Collect the results\n",
    "numbers_all = cubedRDD.collect()\n",
    "\n",
    "# Print the numbers from numbers_all\n",
    "for numb in numbers_all:\n",
    "    print(numb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff7e6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of lines with the keyword Spark is 3\n",
      "spark error\n",
      "spark error\n",
      "spark warnings\n"
     ]
    }
   ],
   "source": [
    "fileRDD = sc.textFile('./logs.txt')\n",
    "\n",
    "# Filter the fileRDD to select lines with Spark keyword\n",
    "fileRDD_filter = fileRDD.filter(lambda line: 'spark' in line)\n",
    "\n",
    "# How many lines are there in fileRDD?\n",
    "print(\"The total number of lines with the keyword Spark is\", fileRDD_filter.count())\n",
    "\n",
    "# Print the first four lines of fileRDD\n",
    "for line in fileRDD_filter.take(4): \n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95271c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD = sc.parallelize([\"hello world\", \"how are you\"])\n",
    "RDD_flatmap = RDD.flatMap(lambda x: x.split(\" \"))\n",
    "RDD_flatmap.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd763dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very bad  error',\n",
       " 'spark error',\n",
       " 'spark error',\n",
       " 'very good error',\n",
       " 'spark warnings']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputRDD = sc.textFile(\"logs.txt\")\n",
    "errorRDD = inputRDD.filter(lambda x: \"error\" in x.split())\n",
    "warningsRDD = inputRDD.filter(lambda x: \"warnings\" in x.split())\n",
    "combinedRDD = errorRDD.union(warningsRDD)\n",
    "combinedRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b06635c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'very bad  error'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057153b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very bad  error', 'spark error']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c242ac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af20ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (3, 4), (3, 6), (4, 5)]\n",
      "[(1, 2), (3, 10), (4, 5)]\n",
      "Key 1 has 2 Counts\n",
      "Key 3 has 10 Counts\n",
      "Key 4 has 5 Counts\n"
     ]
    }
   ],
   "source": [
    "# Create PairRDD Rdd with key value pairs\n",
    "Rdd = sc.parallelize([(1, 2), (3, 4), (3, 6), (4, 5)])\n",
    "print(Rdd.collect())\n",
    "# Apply reduceByKey() operation on Rdd\n",
    "Rdd_Reduced = Rdd.reduceByKey(lambda x, y: x + y)\n",
    "print(Rdd_Reduced.collect())\n",
    "\n",
    "# Iterate over the result and print the output\n",
    "for num in Rdd_Reduced.collect(): \n",
    "  print(\"Key {} has {} Counts\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7f08bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 5), (3, 10), (1, 2)]\n",
      "Key 4 has 5 Counts\n",
      "Key 3 has 10 Counts\n",
      "Key 1 has 2 Counts\n"
     ]
    }
   ],
   "source": [
    "# Sort the reduced RDD with the key by descending order\n",
    "Rdd_Reduced_Sort = Rdd_Reduced.sortByKey(ascending=False)\n",
    "print(Rdd_Reduced_Sort.collect())\n",
    "# Iterate over the result and retrieve all the elements of the RDD\n",
    "for num in Rdd_Reduced_Sort.collect():\n",
    "  print(\"Key {} has {} Counts\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25f53c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_INT = sc.parallelize(range(1, 11), 3)\n",
    "# RDD_INT.saveAsTextFile('./RDD_INT.txt')\n",
    "# RDD_INT.coalesce(1).saveAsTextFile('./RDD_INT_all_partitions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f54504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = range(1, 11)\n",
    "RDD = sc.parallelize(x)\n",
    "RDD.reduce(lambda x, y : x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aefef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 1], ['a', 2], ['b', 3]]\n",
      "[{'a': 1}, {'a': 2}, {'b': 3}]\n"
     ]
    }
   ],
   "source": [
    "a = [['a', 1], ['a', 2], ['b', 3]]\n",
    "b = [{'a': 1}, {'a': 2}, {'b': 3}]\n",
    "RDD_a = sc.parallelize(a)\n",
    "RDD_b = sc.parallelize(b)\n",
    "print(RDD_a.collect())\n",
    "print(RDD_b.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f2f7d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 2), ('b', 1)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_a.countByKey().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45e4799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD_b.countByKey().items() it will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8163d293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of total is <class 'collections.defaultdict'>\n",
      "key 1 has 1 counts\n",
      "key 3 has 2 counts\n",
      "key 4 has 1 counts\n"
     ]
    }
   ],
   "source": [
    "Rdd = sc.parallelize([(1, 2), (3, 4), (3, 6), (4, 5)])\n",
    "# Count the unique keys\n",
    "total = Rdd.countByKey()\n",
    "\n",
    "# What is the type of total?\n",
    "print(\"The type of total is\", type(total))\n",
    "\n",
    "# Iterate over the total and print the output\n",
    "for k, v in total.items(): \n",
    "  print(\"key\", k, \"has\", v, \"counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a64c5",
   "metadata": {},
   "source": [
    "Create a base RDD and transform it\n",
    "The volume of unstructured data (log lines, images, binary files) in existence is growing dramatically, and PySpark is an excellent framework for analyzing this type of data through RDDs. In this 3 part exercise, you will write code that calculates the most common words from Complete Works of William Shakespeare.\n",
    "\n",
    "Here are the brief steps for writing the word counting program:\n",
    "\n",
    "Create a base RDD from Complete_Shakespeare.txt file.\n",
    "Use RDD transformation to create a long list of words from each element of the base RDD.\n",
    "Remove stop words from your data.\n",
    "Create pair RDD where each element is a pair tuple of ('w', 1)\n",
    "Group the elements of the pair RDD by key (word) and add up their values.\n",
    "Swap the keys (word) and values (counts) so that keys is count and value is the word.\n",
    "Finally, sort the RDD by descending order and print the 10 most frequent words and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18a6a6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in splitRDD: 128576\n"
     ]
    }
   ],
   "source": [
    "# Create a baseRDD from the file path\n",
    "baseRDD = sc.textFile('./shakespare.txt')\n",
    "\n",
    "# Split the lines of baseRDD into words\n",
    "splitRDD = baseRDD.flatMap(lambda x: x.split())\n",
    "\n",
    "# Count the total number of words\n",
    "print(\"Total number of words in splitRDD:\", splitRDD.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da010e13",
   "metadata": {},
   "source": [
    "Remove stop words and reduce the dataset\n",
    "After splitting the lines in the file into a long list of words in the previous exercise, in the next step, you'll remove stop words from your data. Stop words are common words that are often uninteresting. For example \"I\", \"the\", \"a\" etc., are stop words. You can remove many obvious stop words with a list of your own. But for this exercise, you will just remove the stop words from a curated list stop_words provided to you in your environment.\n",
    "\n",
    "After removing stop words, you'll next create a pair RDD where each element is a pair tuple (k, v) where k is the key and v is the value. In this example, pair RDD is composed of (w, 1) where w is for each word in the RDD and 1 is a number. Finally, you'll combine the values with the same key from the pair RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b602c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i',\n",
    " 'me',\n",
    " 'my',\n",
    " 'myself',\n",
    " 'we',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'you',\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\n",
    " 'he',\n",
    " 'him',\n",
    " 'his',\n",
    " 'himself',\n",
    " 'she',\n",
    " 'her',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'it',\n",
    " 'its',\n",
    " 'itself',\n",
    " 'they',\n",
    " 'them',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'themselves',\n",
    " 'what',\n",
    " 'which',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'this',\n",
    " 'that',\n",
    " 'these',\n",
    " 'those',\n",
    " 'am',\n",
    " 'is',\n",
    " 'are',\n",
    " 'was',\n",
    " 'were',\n",
    " 'be',\n",
    " 'been',\n",
    " 'being',\n",
    " 'have',\n",
    " 'has',\n",
    " 'had',\n",
    " 'having',\n",
    " 'do',\n",
    " 'does',\n",
    " 'did',\n",
    " 'doing',\n",
    " 'a',\n",
    " 'an',\n",
    " 'the',\n",
    " 'and',\n",
    " 'but',\n",
    " 'if',\n",
    " 'or',\n",
    " 'because',\n",
    " 'as',\n",
    " 'until',\n",
    " 'while',\n",
    " 'of',\n",
    " 'at',\n",
    " 'by',\n",
    " 'for',\n",
    " 'with',\n",
    " 'about',\n",
    " 'against',\n",
    " 'between',\n",
    " 'into',\n",
    " 'through',\n",
    " 'during',\n",
    " 'before',\n",
    " 'after',\n",
    " 'above',\n",
    " 'below',\n",
    " 'to',\n",
    " 'from',\n",
    " 'up',\n",
    " 'down',\n",
    " 'in',\n",
    " 'out',\n",
    " 'on',\n",
    " 'off',\n",
    " 'over',\n",
    " 'under',\n",
    " 'again',\n",
    " 'further',\n",
    " 'then',\n",
    " 'once',\n",
    " 'here',\n",
    " 'there',\n",
    " 'when',\n",
    " 'where',\n",
    " 'why',\n",
    " 'how',\n",
    " 'all',\n",
    " 'any',\n",
    " 'both',\n",
    " 'each',\n",
    " 'few',\n",
    " 'more',\n",
    " 'most',\n",
    " 'other',\n",
    " 'some',\n",
    " 'such',\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'only',\n",
    " 'own',\n",
    " 'same',\n",
    " 'so',\n",
    " 'than',\n",
    " 'too',\n",
    " 'very',\n",
    " 'can',\n",
    " 'will',\n",
    " 'just',\n",
    " 'don',\n",
    " 'should',\n",
    " 'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8fcc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the words in lower case and remove stop words from the stop_words curated list\n",
    "splitRDD_no_stop = splitRDD.filter(lambda x: x.lower() not in stop_words)\n",
    "# Create a tuple of the word and 1 \n",
    "splitRDD_no_stop_words = splitRDD_no_stop.map(lambda w: (w, 1))\n",
    "# Count of the number of occurences of each word\n",
    "resultRDD = splitRDD_no_stop_words.reduceByKey(lambda x, y: x + y)\n",
    "# resultRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28228bc6",
   "metadata": {},
   "source": [
    "Print word frequencies\n",
    "After combining the values (counts) with the same key (word), in this exercise, you'll return the first 10 word frequencies. You could have retrieved all the elements at once using collect() but it is bad practice and not recommended. RDDs can be huge: you may run out of memory and crash your computer..\n",
    "\n",
    "What if we want to return the top 10 words? For this, first you'll need to swap the key (word) and values (counts) so that keys is count and value is the word. After you swap the key and value in the tuple, you'll sort the pair RDD based on the key (count). This way it is easy to sort the RDD based on the key rather than the key using sortByKey operation in PySpark. Finally, you'll return the top 10 words from the sorted RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5aedc58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Project', 9)\n",
      "('EBook', 1)\n",
      "('Shakespeare', 12)\n",
      "('use', 38)\n",
      "('anyone', 1)\n",
      "('anywhere', 1)\n",
      "('restrictions', 1)\n",
      "('whatsoever.', 1)\n",
      "('may', 162)\n",
      "('it,', 74)\n",
      "thou,650\n",
      "thy,574\n",
      "shall,393\n",
      "would,311\n",
      "good,295\n",
      "thee,286\n",
      "love,273\n",
      "Enter,269\n",
      "th',254\n",
      "make,225\n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 words and their frequencies from the input RDD\n",
    "for word in resultRDD.take(10):\n",
    "    print(word)\n",
    "\n",
    "# Swap the keys and values from the input RDD\n",
    "resultRDD_swap = resultRDD.map(lambda x: (x[1], x[0]))\n",
    "# print(resultRDD_swap.take(5))\n",
    "# Sort the keys in descending order\n",
    "resultRDD_swap_sort = resultRDD_swap.sortByKey(ascending=False)\n",
    "\n",
    "# # Show the top 10 most frequent words and their frequencies from the sorted RDD\n",
    "for word in resultRDD_swap_sort.take(10):\n",
    "    print(\"{},{}\". format(word[1], word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09cef9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of names_df is <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+--------+---+\n",
      "|    Name|Age|\n",
      "+--------+---+\n",
      "|    Mona| 20|\n",
      "|Jennifer| 34|\n",
      "|    John| 20|\n",
      "|     Jim| 26|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_list = [('Mona', 20), ('Jennifer', 34), ('John', 20), ('Jim', 26)]\n",
    "# Create an RDD from the list\n",
    "rdd = sc.parallelize(sample_list)\n",
    "\n",
    "# Create a PySpark DataFrame\n",
    "names_df = my_spark.createDataFrame(rdd, schema=['Name', 'Age'])\n",
    "\n",
    "# Check the type of names_df\n",
    "print(\"The type of names_df is\", type(names_df))\n",
    "\n",
    "names_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "338c1668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of people_df is <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+---+---------+--------------+------+-------------+\n",
      "|_c0|person_id|          name|   sex|date of birth|\n",
      "+---+---------+--------------+------+-------------+\n",
      "|  0|      100|Penelope Lewis|female|   1990-08-31|\n",
      "|  1|      101| David Anthony|  male|   1971-10-14|\n",
      "|  2|      102|     Ida Shipp|female|   1962-05-24|\n",
      "|  3|      103|  Joanna Moore|female|   2017-03-10|\n",
      "|  4|      104|Lisandra Ortiz|female|   2020-08-05|\n",
      "+---+---------+--------------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = './people.csv'\n",
    "\n",
    "# Create an DataFrame from file_path\n",
    "people_df = my_spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Check the type of people_df\n",
    "print(\"The type of people_df is\", type(people_df))\n",
    "\n",
    "people_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "624cc244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+------+-------------+\n",
      "|_c0|person_id|            name|   sex|date of birth|\n",
      "+---+---------+----------------+------+-------------+\n",
      "|  0|      100|  Penelope Lewis|female|   1990-08-31|\n",
      "|  1|      101|   David Anthony|  male|   1971-10-14|\n",
      "|  2|      102|       Ida Shipp|female|   1962-05-24|\n",
      "|  3|      103|    Joanna Moore|female|   2017-03-10|\n",
      "|  4|      104|  Lisandra Ortiz|female|   2020-08-05|\n",
      "|  5|      105|   David Simmons|  male|   1999-12-30|\n",
      "|  6|      106|   Edward Hudson|  male|   1983-05-09|\n",
      "|  7|      107|    Albert Jones|  male|   1990-09-13|\n",
      "|  8|      108|Leonard Cavender|  male|   1958-08-08|\n",
      "|  9|      109|  Everett Vadala|  male|   2005-05-24|\n",
      "+---+---------+----------------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "There are 100000 rows in the people_df DataFrame.\n",
      "There are 5 columns in the people_df DataFrame and their names are ['_c0', 'person_id', 'name', 'sex', 'date of birth']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 observations \n",
    "people_df.show(10)\n",
    "\n",
    "# Count the number of rows \n",
    "print(\"There are {} rows in the people_df DataFrame.\".format(people_df.count()))\n",
    "\n",
    "# Count the number of columns and their names\n",
    "print(\"There are {} columns in the people_df DataFrame and their names are {}\".format(len(people_df.columns), people_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c3d4d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-------------+\n",
      "|            name|   sex|date of birth|\n",
      "+----------------+------+-------------+\n",
      "|  Penelope Lewis|female|   1990-08-31|\n",
      "|   David Anthony|  male|   1971-10-14|\n",
      "|       Ida Shipp|female|   1962-05-24|\n",
      "|    Joanna Moore|female|   2017-03-10|\n",
      "|  Lisandra Ortiz|female|   2020-08-05|\n",
      "|   David Simmons|  male|   1999-12-30|\n",
      "|   Edward Hudson|  male|   1983-05-09|\n",
      "|    Albert Jones|  male|   1990-09-13|\n",
      "|Leonard Cavender|  male|   1958-08-08|\n",
      "|  Everett Vadala|  male|   2005-05-24|\n",
      "+----------------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "There were 100000 rows before removing duplicates, and 99998 rows after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "# Select name, sex and date of birth columns\n",
    "people_df_sub = people_df.select('name', 'sex', 'date of birth')\n",
    "\n",
    "# Print the first 10 observations from people_df_sub\n",
    "people_df_sub.show(10)\n",
    "\n",
    "# Remove duplicate entries from people_df_sub\n",
    "people_df_sub_nodup = people_df_sub.dropDuplicates()\n",
    "\n",
    "# Count the number of rows\n",
    "print(\"There were {} rows before removing duplicates, and {} rows after removing duplicates\".format(people_df_sub.count(), people_df_sub_nodup.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42d6bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+-------------+\n",
      "|          name|gender|date of birth|\n",
      "+--------------+------+-------------+\n",
      "|Penelope Lewis|female|   1990-08-31|\n",
      "| David Anthony|  male|   1971-10-14|\n",
      "|     Ida Shipp|female|   1962-05-24|\n",
      "+--------------+------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub = people_df_sub.withColumnRenamed('sex', 'gender')\n",
    "people_df_sub.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "533dd647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|  male|49066|\n",
      "|female|49014|\n",
      "|  null| 1920|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub.groupBy('gender').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff900d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- date of birth: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9567a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------+-------------+\n",
      "|summary|         name|gender|date of birth|\n",
      "+-------+-------------+------+-------------+\n",
      "|  count|       100000| 98080|       100000|\n",
      "|   mean|         null|  null|         null|\n",
      "| stddev|         null|  null|         null|\n",
      "|    min|Aaron Addesso|female|   1899-08-28|\n",
      "|    max|  Zulma Biggs|  male|   2084-11-17|\n",
      "+-------+-------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6da36200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Penelope Lewis', gender='female', date of birth='1990-08-31'),\n",
       " Row(name='David Anthony', gender='male', date of birth='1971-10-14'),\n",
       " Row(name='Ida Shipp', gender='female', date of birth='1962-05-24')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_df_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9282928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            name|\n",
      "+----------------+\n",
      "|  Penelope Lewis|\n",
      "|   David Anthony|\n",
      "|       Ida Shipp|\n",
      "|    Joanna Moore|\n",
      "|  Lisandra Ortiz|\n",
      "|   David Simmons|\n",
      "|   Edward Hudson|\n",
      "|    Albert Jones|\n",
      "|Leonard Cavender|\n",
      "|  Everett Vadala|\n",
      "+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary table \"people\"\n",
    "people_df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# Construct a query to select the names of the people from the temporary table \"people\"\n",
    "query = 'SELECT name FROM people'\n",
    "\n",
    "# Assign the result of Spark's query to people_df_names\n",
    "people_df_names = my_spark.sql(query)\n",
    "\n",
    "# Print the top 10 names of the people\n",
    "people_df_names.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b07f124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49014 rows in the people_female_df and 49066 rows in the people_male_df DataFrames\n"
     ]
    }
   ],
   "source": [
    "# Filter the people table to select female sex \n",
    "people_female_df = my_spark.sql('SELECT * FROM people WHERE sex=\"female\"')\n",
    "\n",
    "# Filter the people table DataFrame to select male sex\n",
    "people_male_df = my_spark.sql('SELECT * from people where sex=\"male\"')\n",
    "\n",
    "# Count the number of rows in both DataFrames\n",
    "print(\"There are {} rows in the people_female_df and {} rows in the people_male_df DataFrames\".format(people_female_df.count(), people_male_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e02bdcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|   sex|sex_count|\n",
      "+------+---------+\n",
      "|  male|    49066|\n",
      "|female|    49014|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_spark.sql('''\n",
    "    SELECT\n",
    "        sex,\n",
    "        count(*) sex_count\n",
    "    FROM\n",
    "        people\n",
    "    WHERE\n",
    "        sex IS NOT NULL\n",
    "    GROUP BY\n",
    "        sex\n",
    "    ORDER BY\n",
    "        count(*) DESC\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c413c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df_sub = people_df_sub.withColumn(\n",
    "    'age',\n",
    "    F.floor(F.datediff(F.current_date(),'date of birth') / 365.25) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d2b55a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df_sub_name_age = people_df_sub.select('name', 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acfc8d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+\n",
      "|          name|age|\n",
      "+--------------+---+\n",
      "|Penelope Lewis| 32|\n",
      "| David Anthony| 51|\n",
      "|     Ida Shipp| 60|\n",
      "+--------------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub_name_age.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "863c85a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Photo: string (nullable = true)\n",
      " |-- Nationality: string (nullable = true)\n",
      " |-- Flag: string (nullable = true)\n",
      " |-- Overall: integer (nullable = true)\n",
      " |-- Potential: integer (nullable = true)\n",
      " |-- Club: string (nullable = true)\n",
      " |-- Club Logo: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      " |-- Wage: string (nullable = true)\n",
      " |-- Special: integer (nullable = true)\n",
      " |-- Acceleration: string (nullable = true)\n",
      " |-- Aggression: string (nullable = true)\n",
      " |-- Agility: string (nullable = true)\n",
      " |-- Balance: string (nullable = true)\n",
      " |-- Ball control: string (nullable = true)\n",
      " |-- Composure: string (nullable = true)\n",
      " |-- Crossing: string (nullable = true)\n",
      " |-- Curve: string (nullable = true)\n",
      " |-- Dribbling: string (nullable = true)\n",
      " |-- Finishing: string (nullable = true)\n",
      " |-- Free kick accuracy: string (nullable = true)\n",
      " |-- GK diving: string (nullable = true)\n",
      " |-- GK handling: string (nullable = true)\n",
      " |-- GK kicking: string (nullable = true)\n",
      " |-- GK positioning: string (nullable = true)\n",
      " |-- GK reflexes: string (nullable = true)\n",
      " |-- Heading accuracy: string (nullable = true)\n",
      " |-- Interceptions: string (nullable = true)\n",
      " |-- Jumping: string (nullable = true)\n",
      " |-- Long passing: string (nullable = true)\n",
      " |-- Long shots: string (nullable = true)\n",
      " |-- Marking: string (nullable = true)\n",
      " |-- Penalties: string (nullable = true)\n",
      " |-- Positioning: string (nullable = true)\n",
      " |-- Reactions: string (nullable = true)\n",
      " |-- Short passing: string (nullable = true)\n",
      " |-- Shot power: string (nullable = true)\n",
      " |-- Sliding tackle: string (nullable = true)\n",
      " |-- Sprint speed: string (nullable = true)\n",
      " |-- Stamina: string (nullable = true)\n",
      " |-- Standing tackle: string (nullable = true)\n",
      " |-- Strength: string (nullable = true)\n",
      " |-- Vision: string (nullable = true)\n",
      " |-- Volleys: string (nullable = true)\n",
      " |-- CAM: double (nullable = true)\n",
      " |-- CB: double (nullable = true)\n",
      " |-- CDM: double (nullable = true)\n",
      " |-- CF: double (nullable = true)\n",
      " |-- CM: double (nullable = true)\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- LAM: double (nullable = true)\n",
      " |-- LB: double (nullable = true)\n",
      " |-- LCB: double (nullable = true)\n",
      " |-- LCM: double (nullable = true)\n",
      " |-- LDM: double (nullable = true)\n",
      " |-- LF: double (nullable = true)\n",
      " |-- LM: double (nullable = true)\n",
      " |-- LS: double (nullable = true)\n",
      " |-- LW: double (nullable = true)\n",
      " |-- LWB: double (nullable = true)\n",
      " |-- Preferred Positions: string (nullable = true)\n",
      " |-- RAM: double (nullable = true)\n",
      " |-- RB: double (nullable = true)\n",
      " |-- RCB: double (nullable = true)\n",
      " |-- RCM: double (nullable = true)\n",
      " |-- RDM: double (nullable = true)\n",
      " |-- RF: double (nullable = true)\n",
      " |-- RM: double (nullable = true)\n",
      " |-- RS: double (nullable = true)\n",
      " |-- RW: double (nullable = true)\n",
      " |-- RWB: double (nullable = true)\n",
      " |-- ST: double (nullable = true)\n",
      "\n",
      "+---+-----------------+---+--------------------+-----------+--------------------+-------+---------+-------------------+--------------------+------+-----+-------+------------+----------+-------+-------+------------+---------+--------+-----+---------+---------+------------------+---------+-----------+----------+--------------+-----------+----------------+-------------+-------+------------+----------+-------+---------+-----------+---------+-------------+----------+--------------+------------+-------+---------------+--------+------+-------+----+----+----+----+----+------+----+----+----+----+----+----+----+----+----+----+-------------------+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|_c0|             Name|Age|               Photo|Nationality|                Flag|Overall|Potential|               Club|           Club Logo| Value| Wage|Special|Acceleration|Aggression|Agility|Balance|Ball control|Composure|Crossing|Curve|Dribbling|Finishing|Free kick accuracy|GK diving|GK handling|GK kicking|GK positioning|GK reflexes|Heading accuracy|Interceptions|Jumping|Long passing|Long shots|Marking|Penalties|Positioning|Reactions|Short passing|Shot power|Sliding tackle|Sprint speed|Stamina|Standing tackle|Strength|Vision|Volleys| CAM|  CB| CDM|  CF|  CM|    ID| LAM|  LB| LCB| LCM| LDM|  LF|  LM|  LS|  LW| LWB|Preferred Positions| RAM|  RB| RCB| RCM| RDM|  RF|  RM|  RS|  RW| RWB|  ST|\n",
      "+---+-----------------+---+--------------------+-----------+--------------------+-------+---------+-------------------+--------------------+------+-----+-------+------------+----------+-------+-------+------------+---------+--------+-----+---------+---------+------------------+---------+-----------+----------+--------------+-----------+----------------+-------------+-------+------------+----------+-------+---------+-----------+---------+-------------+----------+--------------+------------+-------+---------------+--------+------+-------+----+----+----+----+----+------+----+----+----+----+----+----+----+----+----+----+-------------------+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|  0|Cristiano Ronaldo| 32|https://cdn.sofif...|   Portugal|https://cdn.sofif...|     94|       94|     Real Madrid CF|https://cdn.sofif...|€95.5M|€565K|   2228|          89|        63|     89|     63|          93|       95|      85|   81|       91|       94|                76|        7|         11|        15|            14|         11|              88|           29|     95|          77|        92|     22|       85|         95|       96|           83|        94|            23|          91|     92|             31|      80|    85|     88|89.0|53.0|62.0|91.0|82.0| 20801|89.0|61.0|53.0|82.0|62.0|91.0|89.0|92.0|91.0|66.0|             ST LW |89.0|61.0|53.0|82.0|62.0|91.0|89.0|92.0|91.0|66.0|92.0|\n",
      "|  1|         L. Messi| 30|https://cdn.sofif...|  Argentina|https://cdn.sofif...|     93|       93|       FC Barcelona|https://cdn.sofif...| €105M|€565K|   2154|          92|        48|     90|     95|          95|       96|      77|   89|       97|       95|                90|        6|         11|        15|            14|          8|              71|           22|     68|          87|        88|     13|       74|         93|       95|           88|        85|            26|          87|     73|             28|      59|    90|     85|92.0|45.0|59.0|92.0|84.0|158023|92.0|57.0|45.0|84.0|59.0|92.0|90.0|88.0|91.0|62.0|                RW |92.0|57.0|45.0|84.0|59.0|92.0|90.0|88.0|91.0|62.0|88.0|\n",
      "|  2|           Neymar| 25|https://cdn.sofif...|     Brazil|https://cdn.sofif...|     92|       94|Paris Saint-Germain|https://cdn.sofif...| €123M|€280K|   2100|          94|        56|     96|     82|          95|       92|      75|   81|       96|       89|                84|        9|          9|        15|            15|         11|              62|           36|     61|          75|        77|     21|       81|         90|       88|           81|        80|            33|          90|     78|             24|      53|    80|     83|88.0|46.0|59.0|88.0|79.0|190871|88.0|59.0|46.0|79.0|59.0|88.0|87.0|84.0|89.0|64.0|                LW |88.0|59.0|46.0|79.0|59.0|88.0|87.0|84.0|89.0|64.0|84.0|\n",
      "|  3|        L. Suárez| 30|https://cdn.sofif...|    Uruguay|https://cdn.sofif...|     92|       92|       FC Barcelona|https://cdn.sofif...|  €97M|€510K|   2291|          88|        78|     86|     60|          91|       83|      77|   86|       86|       94|                84|       27|         25|        31|            33|         37|              77|           41|     69|          64|        86|     30|       85|         92|       93|           83|        87|            38|          77|     89|             45|      80|    84|     88|87.0|58.0|65.0|88.0|80.0|176580|87.0|64.0|58.0|80.0|65.0|88.0|85.0|88.0|87.0|68.0|                ST |87.0|64.0|58.0|80.0|65.0|88.0|85.0|88.0|87.0|68.0|88.0|\n",
      "|  4|         M. Neuer| 31|https://cdn.sofif...|    Germany|https://cdn.sofif...|     92|       92|   FC Bayern Munich|https://cdn.sofif...|  €61M|€230K|   1493|          58|        29|     52|     35|          48|       70|      15|   14|       30|       13|                11|       91|         90|        95|            91|         89|              25|           30|     78|          59|        16|     10|       47|         12|       85|           55|        25|            11|          61|     44|             10|      83|    70|     11|null|null|null|null|null|167495|null|null|null|null|null|null|null|null|null|null|                GK |null|null|null|null|null|null|null|null|null|null|null|\n",
      "|  5|   R. Lewandowski| 28|https://cdn.sofif...|     Poland|https://cdn.sofif...|     91|       91|   FC Bayern Munich|https://cdn.sofif...|  €92M|€355K|   2143|          79|        80|     78|     80|          89|       87|      62|   77|       85|       91|                84|       15|          6|        12|             8|         10|              85|           39|     84|          65|        83|     25|       81|         91|       91|           83|        88|            19|          83|     79|             42|      84|    78|     87|84.0|57.0|62.0|87.0|78.0|188545|84.0|58.0|57.0|78.0|62.0|87.0|82.0|88.0|84.0|61.0|                ST |84.0|58.0|57.0|78.0|62.0|87.0|82.0|88.0|84.0|61.0|88.0|\n",
      "|  6|           De Gea| 26|https://cdn.sofif...|      Spain|https://cdn.sofif...|     90|       92|  Manchester United|https://cdn.sofif...|€64.5M|€215K|   1458|          57|        38|     60|     43|          42|       64|      17|   21|       18|       13|                19|       90|         85|        87|            86|         90|              21|           30|     67|          51|        12|     13|       40|         12|       88|           50|        31|            13|          58|     40|             21|      64|    68|     13|null|null|null|null|null|193080|null|null|null|null|null|null|null|null|null|null|                GK |null|null|null|null|null|null|null|null|null|null|null|\n",
      "|  7|        E. Hazard| 26|https://cdn.sofif...|    Belgium|https://cdn.sofif...|     90|       91|            Chelsea|https://cdn.sofif...|€90.5M|€295K|   2096|          93|        54|     93|     91|          92|       87|      80|   82|       93|       83|                79|       11|         12|         6|             8|          8|              57|           41|     59|          81|        82|     25|       86|         85|       85|           86|        79|            22|          87|     79|             27|      65|    86|     79|88.0|47.0|61.0|87.0|81.0|183277|88.0|59.0|47.0|81.0|61.0|87.0|87.0|82.0|88.0|64.0|                LW |88.0|59.0|47.0|81.0|61.0|87.0|87.0|82.0|88.0|64.0|82.0|\n",
      "|  8|         T. Kroos| 27|https://cdn.sofif...|    Germany|https://cdn.sofif...|     90|       90|     Real Madrid CF|https://cdn.sofif...|  €79M|€340K|   2165|          60|        60|     71|     69|          89|       85|      85|   85|       79|       76|                84|       10|         11|        13|             7|         10|              54|           85|     32|          93|        90|     63|       73|         79|       86|           90|        87|            69|          52|     77|             82|      74|    88|     82|83.0|72.0|82.0|81.0|87.0|182521|83.0|76.0|72.0|87.0|82.0|81.0|81.0|77.0|80.0|78.0|            CDM CM |83.0|76.0|72.0|87.0|82.0|81.0|81.0|77.0|80.0|78.0|77.0|\n",
      "|  9|       G. Higuaín| 29|https://cdn.sofif...|  Argentina|https://cdn.sofif...|     90|       90|           Juventus|https://cdn.sofif...|  €77M|€275K|   1961|          78|        50|     75|     69|          85|       86|      68|   74|       84|       91|                62|        5|         12|         7|             5|         10|              86|           20|     79|          59|        82|     12|       70|         92|       88|           75|        88|            18|          80|     72|             22|      85|    70|     88|81.0|46.0|52.0|84.0|71.0|167664|81.0|51.0|46.0|71.0|52.0|84.0|79.0|87.0|82.0|55.0|                ST |81.0|51.0|46.0|71.0|52.0|84.0|79.0|87.0|82.0|55.0|87.0|\n",
      "+---+-----------------+---+--------------------+-----------+--------------------+-------+---------+-------------------+--------------------+------+-----+-------+------------+----------+-------+-------+------------+---------+--------+-----+---------+---------+------------------+---------+-----------+----------+--------------+-----------+----------------+-------------+-------+------------+----------+-------+---------+-----------+---------+-------------+----------+--------------+------------+-------+---------------+--------+------+-------+----+----+----+----+----+------+----+----+----+----+----+----+----+----+----+----+-------------------+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17981 rows in the fifa_df DataFrame\n"
     ]
    }
   ],
   "source": [
    "file_path = './Fifa2018_dataset.csv'\n",
    "\n",
    "# Load the Dataframe\n",
    "fifa_df = my_spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Check the schema of columns\n",
    "fifa_df.printSchema()\n",
    "\n",
    "# Show the first 10 observations\n",
    "fifa_df.show(10)\n",
    "\n",
    "# Print the total number of rows\n",
    "print(\"There are {} rows in the fifa_df DataFrame\".format(fifa_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb11c8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|              age|\n",
      "+-------+-----------------+\n",
      "|  count|             1140|\n",
      "|   mean|24.20263157894737|\n",
      "| stddev|4.197096712293752|\n",
      "|    min|               16|\n",
      "|    max|               36|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary view of fifa_df\n",
    "fifa_df.createOrReplaceTempView('fifa_df_table')\n",
    "\n",
    "# Construct the \"query\"\n",
    "query = '''SELECT age FROM fifa_df_table WHERE Nationality == \"Germany\"'''\n",
    "\n",
    "# Apply the SQL \"query\"\n",
    "fifa_df_germany_age = my_spark.sql(query)\n",
    "\n",
    "# Generate basic statistics\n",
    "fifa_df_germany_age.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327f4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
